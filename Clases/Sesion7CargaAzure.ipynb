{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOohA0o7gTPpNK795JyQcce"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SsKVmZmW8WTA"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5on6SXVfEqJD","executionInfo":{"status":"ok","timestamp":1749829329238,"user_tz":300,"elapsed":21488,"user":{"displayName":"Angelo Fabara","userId":"12039030843080192072"}}},"outputs":[],"source":["# Instalar SDK Java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","source":["# Descargar Spark 3.4.3\n","\n","!wget -q https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.2-bin-hadoop3.tgz"],"metadata":{"id":"yyXuYaaNE3ss","executionInfo":{"status":"ok","timestamp":1749829354504,"user_tz":300,"elapsed":21214,"user":{"displayName":"Angelo Fabara","userId":"12039030843080192072"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Descomprimir el archivo descargado de Spark\n","\n","!tar xf spark-3.4.3-bin-hadoop3.tgz"],"metadata":{"id":"LI3Lf-ueE5cQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# establecer las variables de entorno\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\""],"metadata":{"id":"oXPEtAtSE7f1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instalar la librería findspark\n","\n","!pip install -q findspark"],"metadata":{"id":"9_ih0g2lE9SC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extraer las credenciales desde los Secrets\n","\n","from google.colab import userdata\n","\n","account_key = userdata.get('ACCOUNT_KEY')"],"metadata":{"id":"MjJjNSytL91k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear la sesión de Spark\n","\n","import findspark\n","\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = (SparkSession.builder\n","         .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.6,com.microsoft.azure:azure-storage:8.6.6\")\n","         .config(\"spark.hadoop.fs.azure.account.key.josemtech.blob.core.windows.net\", account_key)\n","         .config(\"spark.hadoop.fs.wasbs.impl\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n","         .config(\"spark.hadoop.fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n","         .getOrCreate())"],"metadata":{"id":"0A0jps9uSQ7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Luctura\n","\n","df = spark.read.parquet(\"wasbs://spark-data@josemtech.blob.core.windows.net/parquet\")\n","\n","df.show()"],"metadata":{"id":"Jpc2VLxiSTxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Escritura\n","\n","df.write.mode(\"overwrite\").parquet(\"wasbs://spark-data@josemtech.blob.core.windows.net/test/\")"],"metadata":{"id":"l8LJAaJ6SWoT"},"execution_count":null,"outputs":[]}]}